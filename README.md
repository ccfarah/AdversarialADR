# Adversarial Attacks, Defenses, & Robustness
A repository compiling SOTA methods in adversarial attacks, defenses, and measures of robustness.
## Adversarial Attacks
Some of the first reported deep learning attacks were documented in Papernot et al. 2016.
![Papernot-MNIST_attacks](https://user-images.githubusercontent.com/30714137/179857022-703fa4b5-231e-4155-b626-f95c4681555b.png)

### *-box Attacks

#### White-box Attacks

#### Grey-box Attacks

#### Black-box Attacks

### Data Poisoning

### Physical Attacks

## Adversarial Defenses

### Adversarial Training

### Attack Detection

### Gradient Masking

## Adversarial Robustness

### Corruption

### Perturbation

### Privacy

## References 
- Athalye, A., Engstrom, L., Ilyas, A. and Kwok, K., 2018, July. Synthesizing robust adversarial examples. In International conference on machine learning (pp. 284-293). PMLR. 
- Chakraborty, A., Alam, M., Dey, V., Chattopadhyay, A. and Mukhopadhyay, D., 2018. Adversarial attacks and defences: A survey. arXiv preprint arXiv:1810.00069. 
- Croce, F., Andriushchenko, M., Sehwag, V., Debenedetti, E., Flammarion, N., Chiang, M., Mittal, P. and Hein, M., 2020. RobustBench: a standardized adversarial robustness benchmark. arXiv preprint arXiv:2010.09670. 
- Huang, S., Papernot, N., Goodfellow, I., Duan, Y. and Abbeel, P., 2017. Adversarial attacks on neural network policies. arXiv preprint arXiv:1702.02284. 
- Jia, R. and Liang, P., 2017. Adversarial examples for evaluating reading comprehension systems. arXiv preprint arXiv:1707.07328. 
- Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.B. and Swami, A., 2017, April. Practical black-box attacks against machine learning. In Proceedings of the 2017 ACM on Asia conference on computer and communications security (pp. 506-519). 
- Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B. and Swami, A., 2016, March. The limitations of deep learning in adversarial settings. In 2016 IEEE European symposium on security and privacy (EuroS&P) (pp. 372-387). IEEE. 
- Slack, D., Hilgard, S., Jia, E., Singh, S. and Lakkaraju, H., 2020, February. Fooling lime and shap: Adversarial attacks on post hoc explanation methods. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society (pp. 180-186). 
- Xu, H., Ma, Y., Liu, H.C., Deb, D., Liu, H., Tang, J.L. and Jain, A.K., 2020. Adversarial attacks and defenses in images, graphs and text: A review. International Journal of Automation and Computing, 17(2), pp.151-178. 
- Zügner, D., Akbarnejad, A. and Günnemann, S., 2018, July. Adversarial attacks on neural networks for graph data. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining (pp. 2847-2856).
