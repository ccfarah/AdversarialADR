{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robustbench.data import load_cifar10\n",
    "from robustbench.data import load_cifar10c\n",
    "from robustbench.utils import clean_accuracy\n",
    "from robustbench.utils import load_model\n",
    "import foolbox as fb\n",
    "from autoattack import AutoAttack\n",
    "from test_model import lp_attack\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(model_name:str, dataset:str, threat_model:str):\n",
    "    x_test, y_test = load_cifar10(n_examples=50)\n",
    "    model = load_model(model_name=model_name, dataset=dataset, threat_model=threat_model)\n",
    "    fmodel = fb.PyTorchModel(model, bounds=(0, 1))\n",
    "    _, advs, success = fb.attacks.LinfPGD()(fmodel, x_test.to('cuda:0'), y_test.to('cuda:0'), epsilons=[8/255])\n",
    "    print('Robust accuracy: {:.1%}'.format(1 - success.float().mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_attack(model_name:str, dataset:str, threat_model:str, attacks:list): \n",
    "    x_test, y_test = load_cifar10(n_examples=50)\n",
    "    model = load_model(model_name=model_name, dataset=dataset, threat_model=threat_model)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    adversary = AutoAttack(model, norm='Linf', eps=8/255, version='custom', attacks_to_run=attacks)\n",
    "    adversary.apgd.n_restarts = 1\n",
    "    x_adv = adversary.run_standard_evaluation(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def corruption_attack(corruption_type:str, model_names:list, dataset:str, threat_model:str):\n",
    "    corruptions = [corruption_type]\n",
    "    x_test, y_test = load_cifar10c(n_examples=1000, corruptions=corruptions, severity=5)\n",
    "    for model_name in model_names:\n",
    "        model = load_model(model_name, dataset='cifar10', threat_model=threat_model)\n",
    "        acc = clean_accuracy(model, x_test, y_test)\n",
    "        print(f'Model: {model_name}, CIFAR-10-C accuracy: {acc:.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Robust accuracy: 64.0%\n"
     ]
    }
   ],
   "source": [
    "pgd_attack(model_name='Carmon2019Unlabeled',dataset='cifar10',threat_model='Linf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Standard, CIFAR-10-C accuracy: 74.4%\n",
      "Model: Engstrom2019Robustness, CIFAR-10-C accuracy: 38.8%\n"
     ]
    }
   ],
   "source": [
    "list_of_model_names = ['Standard', 'Engstrom2019Robustness'] #, 'Rice2020Overfitting','Carmon2019Unlabeled']\n",
    "corruption_attack(corruption_type='fog',model_names=list_of_model_names,dataset='cifar10',threat_model='Linf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "using custom version including apgd-ce, apgd-dlr\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/cfarah/AdversarialADR/notebook_overview.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cfarah/AdversarialADR/notebook_overview.ipynb#ch0000003?line=0'>1</a>\u001b[0m list_of_attacks \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mapgd-ce\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mapgd-dlr\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/cfarah/AdversarialADR/notebook_overview.ipynb#ch0000003?line=1'>2</a>\u001b[0m auto_attack(model_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mCarmon2019Unlabeled\u001b[39;49m\u001b[39m'\u001b[39;49m,dataset\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcifar10\u001b[39;49m\u001b[39m'\u001b[39;49m,threat_model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mLinf\u001b[39;49m\u001b[39m'\u001b[39;49m,attacks\u001b[39m=\u001b[39;49mlist_of_attacks)\n",
      "\u001b[1;32m/home/cfarah/AdversarialADR/notebook_overview.ipynb Cell 7\u001b[0m in \u001b[0;36mauto_attack\u001b[0;34m(model_name, dataset, threat_model, attacks)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cfarah/AdversarialADR/notebook_overview.ipynb#ch0000003?line=3'>4</a>\u001b[0m adversary \u001b[39m=\u001b[39m AutoAttack(model, norm\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLinf\u001b[39m\u001b[39m'\u001b[39m, eps\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m, version\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcustom\u001b[39m\u001b[39m'\u001b[39m, attacks_to_run\u001b[39m=\u001b[39mattacks)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cfarah/AdversarialADR/notebook_overview.ipynb#ch0000003?line=4'>5</a>\u001b[0m adversary\u001b[39m.\u001b[39mapgd\u001b[39m.\u001b[39mn_restarts \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/cfarah/AdversarialADR/notebook_overview.ipynb#ch0000003?line=5'>6</a>\u001b[0m x_adv \u001b[39m=\u001b[39m adversary\u001b[39m.\u001b[39;49mrun_standard_evaluation(x_test, y_test)\n",
      "File \u001b[0;32m~/AdversarialADR/env/lib/python3.8/site-packages/autoattack/autoattack.py:84\u001b[0m, in \u001b[0;36mAutoAttack.run_standard_evaluation\u001b[0;34m(self, x_orig, y_orig, bs, return_labels)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39m# checks on type of defense\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mversion \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrand\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 84\u001b[0m     checks\u001b[39m.\u001b[39;49mcheck_randomized(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_logits, x_orig[:bs]\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice),\n\u001b[1;32m     85\u001b[0m         y_orig[:bs]\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice), bs\u001b[39m=\u001b[39;49mbs, logger\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogger)\n\u001b[1;32m     86\u001b[0m n_cls \u001b[39m=\u001b[39m checks\u001b[39m.\u001b[39mcheck_range_output(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_logits, x_orig[:bs]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice),\n\u001b[1;32m     87\u001b[0m     logger\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger)\n\u001b[1;32m     88\u001b[0m checks\u001b[39m.\u001b[39mcheck_dynamic(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, x_orig[:bs]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_tf_model,\n\u001b[1;32m     89\u001b[0m     logger\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger)\n",
      "File \u001b[0;32m~/AdversarialADR/env/lib/python3.8/site-packages/autoattack/checks.py:24\u001b[0m, in \u001b[0;36mcheck_randomized\u001b[0;34m(model, x, y, bs, n, alpha, logger)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     23\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[0;32m---> 24\u001b[0m         output \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     25\u001b[0m         corrcl_curr \u001b[39m=\u001b[39m (output\u001b[39m.\u001b[39mmax(\u001b[39m1\u001b[39m)[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m y)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     26\u001b[0m         corrcl\u001b[39m.\u001b[39mappend(corrcl_curr)\n",
      "File \u001b[0;32m~/AdversarialADR/env/lib/python3.8/site-packages/autoattack/autoattack.py:70\u001b[0m, in \u001b[0;36mAutoAttack.get_logits\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_logits\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_tf_model:\n\u001b[0;32m---> 70\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[1;32m     71\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpredict(x)\n",
      "File \u001b[0;32m~/AdversarialADR/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/AdversarialADR/robustbench/model_zoo/architectures/wide_resnet.py:87\u001b[0m, in \u001b[0;36mWideResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 87\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m     88\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblock1(out)\n\u001b[1;32m     89\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblock2(out)\n",
      "File \u001b[0;32m~/AdversarialADR/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/AdversarialADR/env/lib/python3.8/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/AdversarialADR/env/lib/python3.8/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "list_of_attacks = ['apgd-ce', 'apgd-dlr']\n",
    "auto_attack(model_name='Carmon2019Unlabeled',dataset='cifar10',threat_model='Linf',attacks=list_of_attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afd9502d6efc1e9ca4ae881c778f0a7f12a362a1c96928770e15965bbd9bec4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
